# -*- coding: utf-8 -*-
"""Tweet_Extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vUDyoebC-UE2fnIxEE_MeiO7RhBPF98d
"""

import tweepy
import csv
import json
import time

Access_token = "218099701-8V5hnDctBxVfnLiDJ7cfEgMkV7zRlKypPEqF5rqO"
Access_token_secret = "b5WTg5n9Tnv9YYIomWG1mZLe44ivXrI8nGYDPiWOTyFXX"
API_secret_key ="KdOlLZbuvVkTmHa4XxWuIjjR4Hc33ljwB3VkRdkh2JvLM64y6f"
API_key="ZW6Om6esTswnnI631BVtR2dFl"

auth = tweepy.OAuthHandler(API_key, API_secret_key)
auth.set_access_token(Access_token, Access_token_secret)
api = tweepy.API(auth,wait_on_rate_limit=True, wait_on_rate_limit_notify=True)

Tweet_File = "/Users/Harshitha/Desktop/LargeScaleAnly/Tweets_July31.csv"
privateUser = "/Users/Harshitha/Desktop/LargeScaleAnly/private.txt"

number_of_tweets = 500
tweets_for_csv = []
private_users=[]
f = open("/Users/Harshitha/Desktop/LargeScaleAnly/Data/node_list.txt", "r")
count = 1
for screenName in f.readlines():
    try:
        for tweet in tweepy.Cursor(api.user_timeline, screen_name = screenName).items(number_of_tweets):
            tweets_for_csv.append([tweet.user.screen_name,tweet.text.encode("utf-8")])
        if count % 200 == 0: 
            print(screenName)
        count = count + 1
    except tweepy.TweepError as e:
        private_users.append([screenName,e])
        
with open(Tweet_File, 'w+') as file:
            writer = csv.writer(file, delimiter=',')
            writer.writerows(tweets_for_csv)

with open(privateUser, 'w+') as file1:
            writer = csv.writer(file1, delimiter=',')
            writer.writerows(private_users)



